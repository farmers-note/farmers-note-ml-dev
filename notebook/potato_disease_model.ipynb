{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s_yVF95R0yP",
        "outputId": "87fe82b4-7d53-45a8-caef-dc2e325fc912",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from efficientnet_pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.3)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=f2e6a3132c2be6824c9bb147b65f607ad22fcd8969bb25a2bc1ab254ce40a4ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/3f/43/e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n",
            "\u001b[31mERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
            "    #\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0mDownloading from https://www.kaggle.com/api/v1/datasets/download/shahadhossin567r7455/potato-leaf-disease-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.8M/38.8M [00:01<00:00, 30.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ì…‹ ê²½ë¡œ: /root/.cache/kagglehub/datasets/shahadhossin567r7455/potato-leaf-disease-dataset/versions/1\n",
            "ì‚¬ìš© ì¥ì¹˜: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
        "# ==============================================================================\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "!pip install torchmetrics\n",
        "!pip install kagglehub Â # KaggleHub ì„¤ì¹˜\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import kagglehub # ì„í¬íŠ¸\n",
        "import time\n",
        "import copy\n",
        "from google.colab import drive\n",
        "from collections import Counter # âš ï¸ í´ë˜ìŠ¤ ì¹´ìš´íŠ¸ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€\n",
        "from google.colab import drive #\n",
        "\n",
        "# ë‹¤ìš´ë¡œë“œ ë° ê²½ë¡œ ì„¤ì •\n",
        "path = kagglehub.dataset_download(\"shahadhossin567r7455/potato-leaf-disease-dataset\")\n",
        "\n",
        "print(\"ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ì…‹ ê²½ë¡œ:\", path)\n",
        "\n",
        "# GPU ì‚¬ìš© ì„¤ì •\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (âœ¨ ìµœì¢… í™•ì •: ì‹¤ì œ í´ë” ì´ë¦„ ë°˜ì˜)\n",
        "# ==============================================================================\n",
        "import os\n",
        "\n",
        "# âš ï¸ 'path' ë³€ìˆ˜ëŠ” ë‹¤ìš´ë¡œë“œ ë£¨íŠ¸ ê²½ë¡œë¥¼ ë‹´ê³  ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
        "DATA_ROOT_DOWNLOAD = path\n",
        "\n",
        "# ğŸš¨ [ìˆ˜ì •] ì‹¤ì œ í´ë” ì´ë¦„ì¸ 'Potato Leaf DIsease'ë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
        "DATA_ROOT_FOR_SPLIT = os.path.join(DATA_ROOT_DOWNLOAD, 'Potato Leaf DIsease')\n",
        "\n",
        "print(f\"âœ… ìµœì¢… ë°ì´í„° ë¡œë“œ ê²½ë¡œ (DATA_ROOT_FOR_SPLIT): {DATA_ROOT_FOR_SPLIT}\")\n"
      ],
      "metadata": {
        "id": "SS_T7pFdTfdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6b9972-d82b-48f5-e839-d7cfaaea19bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ìµœì¢… ë°ì´í„° ë¡œë“œ ê²½ë¡œ (DATA_ROOT_FOR_SPLIT): /root/.cache/kagglehub/datasets/shahadhossin567r7455/potato-leaf-disease-dataset/versions/1/Potato Leaf DIsease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ë°ì´í„° ë³€í™˜ ì„¤ì • (ëª¨ë¸ ì¶•ì†Œ ì ìš©)\n",
        "# ==============================================================================\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "BATCH_SIZE = 32 # B0 ëª¨ë¸ì— ë§ì¶° ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ 32ë¡œ ëŠ˜ë ¤ ì†ë„ ê°œì„ \n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.0001 # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ í•™ìŠµë¥ ì€ ê³„ì† ë‚®ê²Œ ìœ ì§€\n",
        "MODEL_NAME = 'efficientnet-b0' # â­ï¸ ëª¨ë¸ì„ EfficientNet-B0ë¡œ ì¶•ì†Œ\n",
        "\n",
        "# EfficientNet-B0ì˜ ê¶Œì¥ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (224x224ë¡œ ìë™ ë³€ê²½ë¨)\n",
        "INPUT_SIZE = EfficientNet.get_image_size(MODEL_NAME)\n",
        "\n",
        "# ë°ì´í„° ì¦ê°• ë° ì •ê·œí™”\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE),\n",
        "        transforms.RandomResizedCrop(INPUT_SIZE),\n",
        "        # ğŸ’¡ [ì¶”ê°€] íšŒì „ ë° ìƒ‰ìƒ ë³€í™” ì¶”ê°€\n",
        "        transforms.RandomRotation(degrees=20),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # ImageNet í†µê³„\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE),\n",
        "        transforms.CenterCrop(INPUT_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "-oTZRBX3TmQM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. ë°ì´í„° ë¡œë“œ ë° DataLoader ìƒì„± (ìˆ˜ì •: ë‹¨ì¼ í´ë” êµ¬ì¡° â†’ Random Split)\n",
        "# ==============================================================================\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "print(\"\\në°ì´í„° ë¡œë”© ë° ì•ˆì „í•œ 90:10 ë¶„í•  ì¤‘...\")\n",
        "\n",
        "# 1. DATA_ROOT ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "# âš ï¸ [ìˆ˜ì •] DATA_ROOT ëŒ€ì‹ , í´ë˜ìŠ¤ í´ë”ê°€ ë“¤ì–´ìˆëŠ” ì •í™•í•œ ê²½ë¡œ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "#    ì´ì „ ê²½ë¡œ ì„¤ì • ì„¹ì…˜ì—ì„œ ì •ì˜í•œ DATA_ROOT_FOR_SPLIT ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "full_dataset = ImageFolder(DATA_ROOT_FOR_SPLIT, data_transforms['train']) # ğŸ’¡ DATA_ROOT_FOR_SPLIT ì‚¬ìš©\n",
        "full_size = len(full_dataset)\n",
        "\n",
        "# 2. ë¹„ìœ¨ ì„¤ì • (90% í•™ìŠµ, 10% ê²€ì¦)\n",
        "train_size = int(0.9 * full_size)\n",
        "val_size = full_size - train_size\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ë¶„ë¦¬ (ê²¹ì¹˜ì§€ ì•ŠìŒì„ ë³´ì¥)\n",
        "train_dataset, val_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size]\n",
        ")\n",
        "\n",
        "# 4. DataLoader ì¬ì •ì˜\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True),\n",
        "    # 'val' í‚¤ì— ê²€ì¦ ë°ì´í„°ì…‹(val_dataset)ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "    'val': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "}\n",
        "\n",
        "# 5. ë©”íƒ€ ì •ë³´ ì—…ë°ì´íŠ¸\n",
        "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
        "class_names = full_dataset.classes\n",
        "NUM_CLASSES = len(class_names)\n",
        "\n",
        "print(f\"í´ë˜ìŠ¤ ê°œìˆ˜: {NUM_CLASSES}\")\n",
        "print(f\"í´ë˜ìŠ¤ ì´ë¦„: {class_names}\")\n",
        "print(f\"âœ… ìƒˆë¡œìš´ í•™ìŠµ ë°ì´í„° í¬ê¸°: {dataset_sizes['train']} (90%)\")\n",
        "print(f\"âœ… ìƒˆë¡œìš´ ê²€ì¦ ë°ì´í„° í¬ê¸°: {dataset_sizes['val']} (10%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuY7fes-Y0XY",
        "outputId": "fcdd16d6-6f62-4fef-b05b-6ff27bc40a00"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ë°ì´í„° ë¡œë”© ë° ì•ˆì „í•œ 90:10 ë¶„í•  ì¤‘...\n",
            "í´ë˜ìŠ¤ ê°œìˆ˜: 7\n",
            "í´ë˜ìŠ¤ ì´ë¦„: ['Early Blight', 'Fungal Diseases', 'Healthy', 'Late Blight', 'Plant Pests', 'Potato Cyst Nematode', 'Potato Virus']\n",
            "âœ… ìƒˆë¡œìš´ í•™ìŠµ ë°ì´í„° í¬ê¸°: 3150 (90%)\n",
            "âœ… ìƒˆë¡œìš´ ê²€ì¦ ë°ì´í„° í¬ê¸°: 350 (10%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. ëª¨ë¸ ì„¤ì • ë° ê°€ì¤‘ì¹˜ ë¶€ì—¬ ì†ì‹¤ í•¨ìˆ˜ ì„¤ì • (âœ¨ B0 ëª¨ë¸ë¡œ ì¶•ì†Œ)\n",
        "# ==============================================================================\n",
        "from collections import Counter\n",
        "import torch.nn as nn\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (Class Imbalance ëŒ€ì²˜)\n",
        "# ==============================================================================\n",
        "from collections import Counter\n",
        "# âš ï¸ image_datasets['train'] ëŒ€ì‹  full_datasetì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "# full_datasetì€ '4. ë°ì´í„° ë¡œë“œ' ì„¹ì…˜ì—ì„œ ì •ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "# full_datasetì€ Subsetì´ ì•„ë‹Œ ImageFolder ê°ì²´ì—¬ì•¼ targetì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "# ë§Œì•½ full_datasetì´ ImageFolder ê°ì²´ì˜€ë‹¤ë©´:\n",
        "# train_targets = full_dataset.targets\n",
        "\n",
        "# ğŸš¨ full_datasetì´ random_split ì „ì˜ ImageFolder ê°ì²´ì˜€ê³ , ê·¸ ê°ì²´ê°€ image_datasets['train']ì— í•´ë‹¹í•œë‹¤ë©´\n",
        "# ìŒ€ ëª¨ë¸ì—ì„œ 'train' ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ,\n",
        "# '4. ë°ì´í„° ë¡œë“œ' ì„¹ì…˜ì—ì„œ ì •ì˜ëœ `full_dataset` ê°ì²´ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "# í˜„ì¬ êµ¬ì¡°ì—ì„œëŠ” full_datasetì´ ImageFolder ê°ì²´ì´ë¯€ë¡œ targets ì†ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "train_targets = full_dataset.targets # ğŸ’¡ [ìˆ˜ì •] full_dataset ê°ì²´ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "class_counts = Counter(train_targets)\n",
        "total_count = sum(class_counts.values())\n",
        "\n",
        "class_weights = [total_count / class_counts[i] for i in range(NUM_CLASSES)]\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "class_weights = class_weights / class_weights.min()\n",
        "\n",
        "print(f\"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ: {class_weights.tolist()}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. EfficientNet-B0 ëª¨ë¸ ë¡œë“œ ë° ë¶„ë¥˜ ë ˆì´ì–´ ëª…ì‹œì  êµì²´ (ìˆ˜ì •)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# ImageNet ê°€ì¤‘ì¹˜ë¡œ EfficientNet-B0 ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "# MODEL_NAME ë³€ìˆ˜ëŠ” ì´ì œ 'efficientnet-b0'ì…ë‹ˆë‹¤.\n",
        "model_ft = EfficientNet.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "# ê¸°ì¡´ ë¶„ë¥˜ ë ˆì´ì–´(_fc)ì˜ ì…ë ¥ í”¼ì²˜ ìˆ˜ í™•ì¸\n",
        "num_ftrs = model_ft._fc.in_features\n",
        "\n",
        "# ğŸ’¡ [ìˆ˜ì •] ì‹¤ì œ ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ìˆ˜ì— ë§ì¶° ìƒˆë¡œìš´ Sequential ë ˆì´ì–´ ì •ì˜ ë° êµì²´\n",
        "#      (Dropout(0.5)ì„ ì¶”ê°€í•˜ì—¬ ê³¼ì í•© ëŒ€ì²˜)\n",
        "model_ft._fc = nn.Sequential(\n",
        "    nn.Dropout(0.5), # 50%ì˜ í™•ë¥ ë¡œ Dropout ì ìš©\n",
        "    nn.Linear(num_ftrs, NUM_CLASSES)\n",
        ")\n",
        "\n",
        "model_ft = model_ft.to(device) # ì¥ì¹˜ì— ë‹¤ì‹œ ì˜¬ë¦½ë‹ˆë‹¤.\n",
        "\n",
        "print(f\"âœ… EfficientNet-B0ì˜ ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´(w/ Dropout)ê°€ {num_ftrs} -> {NUM_CLASSES}ë¡œ ì„±ê³µì ìœ¼ë¡œ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3. Loss, Optimizer, Scheduler ì •ì˜\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# ê³„ì‚°ëœ class_weightsë¥¼ GPU/CPU ì¥ì¹˜ì— ì˜¬ë¦¬ê³  CrossEntropyLossì— ì ìš©\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "# AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš© (ìˆ˜ì •ëœ LEARNING_RATE ì ìš©)\n",
        "optimizer_ft = optim.AdamW(model_ft.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬: 8 ì—í¬í¬ë§ˆë‹¤ 0.5ë°° ê°ì†Œë¡œ ì™„í™”\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.5)\n",
        "\n",
        "print(\"âœ… Loss, Optimizer, Scheduler ì •ì˜ ì™„ë£Œ.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Nczz5VdWMY",
        "outputId": "51387fce-2219-4713-9420-9b9e735e6094"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "âœ… EfficientNet-B0ì˜ ìµœì¢… ë¶„ë¥˜ ë ˆì´ì–´(w/ Dropout)ê°€ 1280 -> 7ë¡œ ì„±ê³µì ìœ¼ë¡œ êµì²´ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "âœ… Loss, Optimizer, Scheduler ì •ì˜ ì™„ë£Œ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ (ìˆ˜ì •ë¨: 'test'ë¥¼ 'val'ë¡œ ë³€ê²½)\n",
        "# ==============================================================================\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
        "\n",
        "        # ğŸ’¡ [ìˆ˜ì •] 'test' ëŒ€ì‹  'val' ë‹¨ê³„ë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # ğŸ’¡ [ìˆ˜ì •] ì¶œë ¥ ë©”ì‹œì§€ì—ì„œ 'test'ë¥¼ 'val'ë¡œ ë³€ê²½\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # ğŸ’¡ [ìˆ˜ì •] 'val' ë‹¨ê³„ì˜ ì •í™•ë„ê°€ ìµœê³  ê¸°ë¡ì¼ ë•Œ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                print(f'-> New best model found! Saving weights with Acc: {best_acc:.4f}')\n",
        "\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        print(f'Epoch Time: {epoch_time:.0f}ì´ˆ')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\ní•™ìŠµ ì™„ë£Œ! ì´ ì‹œê°„: {time_elapsed // 60:.0f}ë¶„ {time_elapsed % 60:.0f}ì´ˆ')\n",
        "    print(f'ìµœê³  ê²€ì¦ ì •í™•ë„: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "nztWbuEedcS0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 7. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ ë° ì €ì¥\n",
        "# ==============================================================================\n",
        "\n",
        "# ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS)\n",
        "\n",
        "# Google Drive ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/disease_model.pth' # âš ï¸ íŒŒì¼ ì´ë¦„ì— weighted ì¶”ê°€\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥\n",
        "torch.save(model_ft.state_dict(), MODEL_SAVE_PATH)\n",
        "print(f\"\\nâœ… ìµœì  ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ {MODEL_SAVE_PATH}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qkqV3csHdx7a",
        "outputId": "2562ae02-f6de-4a94-cd03-07a3ac3a5ff5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 1.6527 Acc: 0.4279\n",
            "val Loss: 1.2831 Acc: 0.5829\n",
            "-> New best model found! Saving weights with Acc: 0.5829\n",
            "Epoch Time: 26ì´ˆ\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.9170 Acc: 0.7133\n",
            "val Loss: 0.6323 Acc: 0.8229\n",
            "-> New best model found! Saving weights with Acc: 0.8229\n",
            "Epoch Time: 25ì´ˆ\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.6106 Acc: 0.7956\n",
            "val Loss: 0.4189 Acc: 0.8743\n",
            "-> New best model found! Saving weights with Acc: 0.8743\n",
            "Epoch Time: 25ì´ˆ\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.5046 Acc: 0.8270\n",
            "val Loss: 0.3530 Acc: 0.8886\n",
            "-> New best model found! Saving weights with Acc: 0.8886\n",
            "Epoch Time: 26ì´ˆ\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.4087 Acc: 0.8619\n",
            "val Loss: 0.2651 Acc: 0.9029\n",
            "-> New best model found! Saving weights with Acc: 0.9029\n",
            "Epoch Time: 26ì´ˆ\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.3635 Acc: 0.8787\n",
            "val Loss: 0.2451 Acc: 0.9257\n",
            "-> New best model found! Saving weights with Acc: 0.9257\n",
            "Epoch Time: 25ì´ˆ\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.3257 Acc: 0.8962\n",
            "val Loss: 0.2243 Acc: 0.9257\n",
            "Epoch Time: 26ì´ˆ\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.2719 Acc: 0.9083\n",
            "val Loss: 0.2099 Acc: 0.9286\n",
            "-> New best model found! Saving weights with Acc: 0.9286\n",
            "Epoch Time: 26ì´ˆ\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.2674 Acc: 0.9156\n",
            "val Loss: 0.2209 Acc: 0.9371\n",
            "-> New best model found! Saving weights with Acc: 0.9371\n",
            "Epoch Time: 26ì´ˆ\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.2562 Acc: 0.9114\n",
            "val Loss: 0.2112 Acc: 0.9343\n",
            "Epoch Time: 25ì´ˆ\n",
            "\n",
            "í•™ìŠµ ì™„ë£Œ! ì´ ì‹œê°„: 4ë¶„ 15ì´ˆ\n",
            "ìµœê³  ê²€ì¦ ì •í™•ë„: 0.9371\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2580603564.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Google Drive ë§ˆìš´íŠ¸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mMODEL_SAVE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/disease_model.pth'\u001b[0m \u001b[0;31m# âš ï¸ íŒŒì¼ ì´ë¦„ì— weighted ì¶”ê°€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c_PDXEx3h9EP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e499323-369e-4d15-f5c4-3b5d06407a94"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ (ì €ì¥ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤)\n",
        "drive.mount('/content/drive')\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/potato_disease_best_model.pth'\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥\n",
        "torch.save(model_ft.state_dict(), MODEL_SAVE_PATH)\n",
        "print(f\"\\nâœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ {MODEL_SAVE_PATH}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6HDp--VlfXu",
        "outputId": "d30a07bb-70db-4f45-e0c5-6537aedb957b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ /content/drive/MyDrive/potato_disease_best_model.pthì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    }
  ]
}