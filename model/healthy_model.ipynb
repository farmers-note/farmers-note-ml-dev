{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbJFcvvdXx7j"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 1. 라이브러리 설치, 임포트 및 장치 설정 (matplotlib 제외)\n",
        "# ==============================================================================\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "!pip install kagglehub\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 장치: {device}\")\n",
        "\n",
        "# 하이퍼파라미터\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "MODEL_NAME = 'efficientnet-b0'\n",
        "INPUT_SIZE = EfficientNet.get_image_size(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. 사용자 정의 데이터셋 및 레이블 설정 (회귀)\n",
        "# ==============================================================================\n",
        "\n",
        "# ⚠️ 모든 작물 클래스에 대한 통합 HEALTH_SCORES 정의\n",
        "# 데이터 따라서 라벨링 수정하기\n",
        "HEALTH_SCORES = {\n",
        "    # 벼 (Rice)\n",
        "    'healthy': 1.00,        # 완벽한 건강\n",
        "    'brown_spot': 0.50,\n",
        "    'leaf_blast': 0.40,\n",
        "    'neck_blast': 0.10,     # 심각한 질병\n",
        "\n",
        "    # 딸기 (Strawberry) - 예시 (실제 폴더 이름으로 수정 필요)\n",
        "    'Strawberry_Healthy': 0.98,\n",
        "    'Strawberry_Leaf_Scotch': 0.35,\n",
        "\n",
        "    # 감자 (Potato) - 예시 (실제 폴더 이름으로 수정 필요)\n",
        "    'Potato_Healthy': 0.95,\n",
        "    'Potato_Early_Blight': 0.45,\n",
        "    'Potato_Late_Blight': 0.15,\n",
        "\n",
        "}\n",
        "\n",
        "class CustomRegressionDataset(Dataset):\n",
        "    \"\"\"ImageFolder를 기반으로 폴더 이름을 HEALTH_SCORES 점수로 변환하는 클래스\"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.data = datasets.ImageFolder(root_dir, transform=transform)\n",
        "\n",
        "        self.health_labels = []\n",
        "        for path, class_index in self.data.samples:\n",
        "            class_name = self.data.classes[class_index]\n",
        "            score = HEALTH_SCORES.get(class_name, 0.5)\n",
        "            self.health_labels.append(score)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, _ = self.data[idx]\n",
        "        score = self.health_labels[idx]\n",
        "        # 회귀 문제이므로 레이블은 float32 타입이어야 합니다.\n",
        "        return img, torch.tensor(score, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "AufW7F4RYSHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. 모델 구조 및 데이터 로드/통합\n",
        "# ==============================================================================\n",
        "\n",
        "# EfficientNet을 회귀용으로 재정의\n",
        "class EfficientNetRegression(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(EfficientNetRegression, self).__init__()\n",
        "        self.base_model = EfficientNet.from_pretrained(model_name)\n",
        "        in_features = self.base_model._fc.in_features\n",
        "        self.base_model._fc = nn.Identity()\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(in_features, 1), # 출력 차원: 1\n",
        "            nn.Sigmoid() # 0과 1 사이의 값으로 강제 출력\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model(x)\n",
        "        output = self.regressor(features)\n",
        "        return output.squeeze(1)\n",
        "\n",
        "# 데이터 변환 및 로드/통합\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE), transforms.RandomResizedCrop(INPUT_SIZE),\n",
        "        transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE), transforms.CenterCrop(INPUT_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "\n",
        "train_datasets = []\n",
        "test_datasets = []\n",
        "\n",
        "# 학습 데이터 통합 (CustomRegressionDataset 사용)\n",
        "for dir_path in ALL_TRAIN_DIRS:\n",
        "    if os.path.exists(dir_path):\n",
        "        current_dataset = CustomRegressionDataset(dir_path, data_transforms['train'])\n",
        "        train_datasets.append(current_dataset)\n",
        "        print(f\"✅ {os.path.basename(dir_path)} 로드 완료. 이미지 수: {len(current_dataset)}\")\n",
        "    else:\n",
        "        print(f\"❌ 경로를 찾을 수 없음 (Train): {dir_path}. 이 데이터셋은 제외됩니다.\")\n",
        "\n",
        "# 검증 데이터 통합\n",
        "for dir_path in ALL_TEST_DIRS:\n",
        "    if os.path.exists(dir_path):\n",
        "        current_dataset = CustomRegressionDataset(dir_path, data_transforms['test'])\n",
        "        test_datasets.append(current_dataset)\n",
        "\n",
        "# 모든 작물 데이터셋을 하나의 큰 데이터셋으로 합치기\n",
        "combined_train_dataset = ConcatDataset(train_datasets)\n",
        "combined_test_dataset = ConcatDataset(test_datasets)\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(combined_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4),\n",
        "    'test': DataLoader(combined_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(combined_train_dataset), 'test': len(combined_test_dataset)}\n",
        "\n",
        "print(f\"\\n✅ 통합 학습 데이터셋 총 크기: {dataset_sizes['train']}\")\n",
        "print(f\"✅ 통합 검증 데이터셋 총 크기: {dataset_sizes['test']}\")\n",
        "\n",
        "# 모델 초기화\n",
        "model_ft = EfficientNetRegression(MODEL_NAME).to(device)\n",
        "\n",
        "# ⚠️ 손실 함수를 회귀용 MSELoss (Mean Squared Error)로 변경\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "gGtXI2ctYWG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. 학습 및 저장\n",
        "# ==============================================================================\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=15):\n",
        "    since = time.time()\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                scheduler.step()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            print(f'{phase} Loss (MSE): {epoch_loss:.6f}')\n",
        "\n",
        "            # 최저 Loss 모델 저장\n",
        "            if phase == 'test' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                print(f'-> New best model found! Saving weights with Loss: {best_loss:.6f}')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\n학습 완료! 총 시간: {time_elapsed // 60:.0f}분 {time_elapsed % 60:.0f}초')\n",
        "    print(f'최고 검증 Loss: {best_loss:.6f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "wk6yJmrtYfhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 모델 학습 실행 및 결과 저장\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# 모델 학습 시작\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "jemgxBLUZELl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트 및 모델 저장\n",
        "drive.mount('/content/drive')\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/multi_crop_health_regression_model.pth'\n",
        "\n",
        "torch.save(model_ft.state_dict(), MODEL_SAVE_PATH)\n",
        "print(f\"\\n✅ 모델 가중치가 {MODEL_SAVE_PATH}에 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "jgaKWaOCZKml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}