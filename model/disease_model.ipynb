{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s_yVF95R0yP",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 1. 라이브러리 설치 및 임포트\n",
        "# ==============================================================================\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "!pip install torchmetrics\n",
        "!pip install kagglehub\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, ConcatDataset # ConcatDataset 사용\n",
        "from torchvision import datasets, transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from google.colab import drive # 모델 저장을 위해 필요\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 장치: {device}\")\n",
        "\n",
        "# 하이퍼파라미터\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "MODEL_NAME = 'efficientnet-b0'\n",
        "INPUT_SIZE = EfficientNet.get_image_size(MODEL_NAME)\n",
        "\n",
        "\n",
        
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. 데이터셋 경로 설정\n",
        "# ==============================================================================\n",
        "# 모든 학습 및 검증 경로를 리스트에 통합\n",
        "\n",
        "path_rice = kagglehub.dataset_download(\"loki4514/rice-leaf-diseases-detection\") #벼 질병 분류 이미지 데이터 api\n",
        "\n",
        "RICE_TRAIN_DIR = os.path.join(path_rice, 'Rice_Leaf_Diease', 'Rice_Leaf_Diease', 'train')\n",
        "RICE_VAL_DIR = os.path.join(path_rice, 'Rice_Leaf_Diease', 'Rice_Leaf_Diease', 'test')\n",
        "\n",
        "\n",
        "ALL_TRAIN_DIRS = [RICE_TRAIN_DIR, STRAWBERRY_TRAIN_DIR, POTATO_TRAIN_DIR]\n",
        "ALL_TEST_DIRS = [RICE_VAL_DIR, STRAWBERRY_VAL_DIR, POTATO_VAL_DIR]\n",
        "\n",
        "\n",
        "print(f\"최종 TRAIN 경로: {TRAIN_DIR}\")\n",
        "print(f\"최종 VAL 경로: {VAL_DIR}\")"
      ],
      "metadata": {
        "id": "SS_T7pFdTfdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. 데이터 로드 및 ConcatDataset 통합\n",
        "# ==============================================================================\n",
        "\n",
        "# 데이터 변환 (모든 작물에 동일하게 적용)\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE), transforms.RandomResizedCrop(INPUT_SIZE),\n",
        "        transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(INPUT_SIZE), transforms.CenterCrop(INPUT_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
        "\n",
        "train_datasets = []\n",
        "test_datasets = []\n",
        "all_class_names = []\n",
        "\n",
        "# 학습 데이터 통합\n",
        "for dir_path in ALL_TRAIN_DIRS:\n",
        "    if os.path.exists(dir_path):\n",
        "        current_dataset = datasets.ImageFolder(dir_path, data_transforms['train'])\n",
        "        train_datasets.append(current_dataset)\n",
        "        all_class_names.extend(current_dataset.classes)\n",
        "        print(f\"✅ {os.path.basename(dir_path)} 로드 완료. 클래스: {current_dataset.classes}\")\n",
        "    else:\n",
        "        print(f\"❌ 경로를 찾을 수 없음 (Train): {dir_path}. 이 데이터셋은 제외됩니다.\")\n",
        "\n",
        "# 검증 데이터 통합\n",
        "for dir_path in ALL_TEST_DIRS:\n",
        "    if os.path.exists(dir_path):\n",
        "        current_dataset = datasets.ImageFolder(dir_path, data_transforms['test'])\n",
        "        test_datasets.append(current_dataset)\n",
        "    # ⚠️ 검증 데이터의 클래스 이름은 학습 데이터와 동일하다고 가정합니다.\n",
        "\n",
        "# 💡 모든 작물 데이터셋을 하나의 큰 데이터셋으로 합치기\n",
        "combined_train_dataset = ConcatDataset(train_datasets)\n",
        "combined_test_dataset = ConcatDataset(test_datasets)\n",
        "\n",
        "# 최종 클래스 목록 (중복 제거)\n",
        "final_class_names = sorted(list(set(all_class_names)))\n",
        "NUM_CLASSES = len(final_class_names)\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(combined_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4),\n",
        "    'test': DataLoader(combined_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(combined_train_dataset), 'test': len(combined_test_dataset)}\n",
        "\n",
        "print(f\"\\n✅ 통합 학습 데이터셋 크기: {dataset_sizes['train']}\")\n",
        "print(f\"✅ 통합 검증 데이터셋 크기: {dataset_sizes['test']}\")\n",
        "print(f\"✅ 통합된 전체 클래스 개수: {NUM_CLASSES}\")"
      ],
      "metadata": {
        "id": "-oTZRBX3TmQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. 모델 설정 (EfficientNet-B0 전이 학습)\n",
        "# ==============================================================================\n",
        "\n",
        "model_ft = EfficientNet.from_pretrained(MODEL_NAME, num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "id": "15Nczz5VdWMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. 모델 학습 함수 (test 키 사용으로 수정)\n",
        "# ==============================================================================\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
        "\n",
        "        # ⚠️ 'val' 대신 'test' 키를 사용합니다.\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train': model.train()\n",
        "            else: model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train': scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # ⚠️ 출력 메시지도 'test'로 수정\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # ⚠️ 'test' 단계의 정확도가 최고 기록일 때 모델을 저장합니다.\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                print(f'-> New best model found! Saving weights with Acc: {best_acc:.4f}')\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\n학습 완료! 총 시간: {time_elapsed // 60:.0f}분 {time_elapsed % 60:.0f}초')\n",
        "    print(f'최고 검증 정확도: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "nztWbuEedcS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. 모델 학습 실행 및 저장\n",
        "# ==============================================================================\n",
        "\n",
        "# 모델 학습 시작\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS)\n"
      ],
      "metadata": {
        "id": "qkqV3csHdx7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 할당된 GPU 정보 확인\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "-VSEopjJluwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 마운트 (저장을 위해 필요합니다)\n",
        "drive.mount('/content/drive')\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/efficientnet_rice_disease_best_model.pth'\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model_ft.state_dict(), MODEL_SAVE_PATH)\n",
        "print(f\"\\n✅ 모델 가중치가 {MODEL_SAVE_PATH}에 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "_6HDp--VlfXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
